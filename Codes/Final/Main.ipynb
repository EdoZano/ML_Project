{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mt\n",
    "import itertools as it\n",
    "import Algorithm as al\n",
    "import Support as sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.read_csv(\"C:/Users/Gulli/Desktop/Uni/Magi/MachineLearningandstat/Progetto_ML/your_dataset.csv\")\n",
    "X=ds.iloc[:,:-1]\n",
    "Y=ds.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.isnull().sum())\n",
    "ds = ds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = sup.Outliers(X, Y)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "Y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4571, 4885,[4571]\n"
     ]
    }
   ],
   "source": [
    "count1=np.sum(Y==1)\n",
    "count_inv=np.sum(Y==-1)\n",
    "print(f'{count1}, {count_inv},{Y.shape-count_inv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sup.Split(X, Y)\n",
    "X_train, X_test = sup.Standardized(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_param = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "pegasos_param = {\n",
    "    'lambda_par': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "logistic_param = {\n",
    "    'lambda_par': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'n': 50} 0.31679217781058666\n",
      "{'lambda_par': 0.001, 'n': 500} 0.33281135279197505\n",
      "{'lambda_par': 1, 'n': 200} 0.5030851191686588\n"
     ]
    }
   ],
   "source": [
    "loss_perc_in, param_perc_in = sup.tuning_par(al.Perceptron, pd.DataFrame(X_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos_in, param_pegasos_in = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit_in, param_logit_in = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc_in, loss_perc_in)\n",
    "print(param_pegasos_in, loss_pegasos_in)\n",
    "print(param_logit_in, loss_logit_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = pd.DataFrame(X_train).corr()\n",
    "high_corr = correlation_matrix[(correlation_matrix > 0.9) | (correlation_matrix < -0.9)]\n",
    "high_corr = high_corr[high_corr != 1.0]\n",
    "high_corr.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model=al.Perceptron(0.1, 200)\n",
    "pegasos_model=al.PegasosSVM(0.001, 500)\n",
    "logistic_model=al.RegLogisticClass(0.01, 500)\n",
    "perceptron_model.fit(X_train, Y_train)\n",
    "pegasos_model.fit(X_train, Y_train)\n",
    "logistic_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.3316884032428622  \n",
      "0-1 Loss Pegasos : 0.31300669721536833  \n",
      "0-1 Loss Logistic : 0.5597462107860416  \n"
     ]
    }
   ],
   "source": [
    "loss_perceptron = sup.Zero_One_Loss(Y_test, perceptron_model.predict(X_test))\n",
    "loss_pegasos = sup.Zero_One_Loss(Y_test, pegasos_model.predict(X_test))\n",
    "loss_logistic = sup.Zero_One_Loss(Y_test, logistic_model.predict(X_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron}  \")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos}  \")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron (Training): 0.3361534975071763  \n",
      "0-1 Loss Perceptron (Test): 0.35671483961931616  \n",
      "0-1 Loss Perceptron (Training): 0.3449161504759027  \n",
      "0-1 Loss Perceptron (Test): 0.35988720479379627  \n",
      "0-1 Loss Perceptron (Training): 0.3370599788487687  \n",
      "0-1 Loss Perceptron (Test): 0.35107507930912935  \n",
      "0-1 Loss Perceptron (Training): 0.34823991539507476  \n",
      "0-1 Loss Perceptron (Test): 0.3683468452590765  \n",
      "0-1 Loss Perceptron (Training): 0.35881553104698594  \n",
      "0-1 Loss Perceptron (Test): 0.37151921043355657  \n",
      "0-1 Loss Perceptron (Training): 0.3038223296570479  \n",
      "0-1 Loss Perceptron (Test): 0.3228762777581953  \n",
      "0-1 Loss Perceptron (Training): 0.6286448103943194  \n",
      "0-1 Loss Perceptron (Test): 0.6087416284807896  \n",
      "0-1 Loss Perceptron (Training): 0.32195195648889563  \n",
      "0-1 Loss Perceptron (Test): 0.35001762425096933  \n",
      "0-1 Loss Perceptron (Training): 0.4768091856775948  \n",
      "0-1 Loss Perceptron (Test): 0.4797321113852661  \n"
     ]
    }
   ],
   "source": [
    "#puoi scrivere funzione\n",
    "np.random.seed(42)\n",
    "models=['Perceptron', 'Pegasos', 'Logistic']\n",
    "for m in models:\n",
    "    for i in [2,5,9,[5,9],[2,5],[2,9],[2,5,9]]:\n",
    "        X_reduced_train=np.delete(X_train, i, axis=1)\n",
    "        X_reduced_test=np.delete(X_test, i, axis=1)\n",
    "        if m == 'Perceptron':\n",
    "            model = al.Perceptron(0.1,200)\n",
    "        elif m == 'Pegasos':\n",
    "            model = al.PegasosSVM(0.001,500)\n",
    "        else:\n",
    "            model = al.RegLogisticClass(0.01,500)\n",
    "        \n",
    "        model.fit(X_reduced_train, Y_train)\n",
    "        y_pred_tr = model.predict(X_reduced_train)\n",
    "        y_pred_test = model.predict(X_reduced_test)\n",
    "   \n",
    "        loss_perceptron_tr = sup.Zero_One_Loss(Y_train, y_pred_tr)\n",
    "        loss_perceptron_test = sup.Zero_One_Loss(Y_test, y_pred_test)\n",
    "        print(f\"0-1 Loss Perceptron (Training): {loss_perceptron_tr}  \")\n",
    "        print(f\"0-1 Loss Perceptron (Test): {loss_perceptron_test}  \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To simplify our analysis we're gonna remove the same feature for all the models\n",
    "X_train=np.delete(X_train, 9, axis=1)\n",
    "X_test=np.delete(X_test, 9, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOING TUNING AGAIN WITHOUT THE LAST FEATURE AND SEEING IF THE BEST PARAMETERS CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_perc, param_perc = sup.tuning_par(al.Perceptron, pd.DataFrame(X_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos, param_pegasos = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit, param_logit = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc, loss_perc)\n",
    "print(param_pegasos, loss_pegasos)\n",
    "print(param_logit, loss_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.3316884032428622  \n",
      "0-1 Loss Pegasos : 0.3260486429326754  \n",
      "0-1 Loss Logistic : 0.48501938667606626  \n"
     ]
    }
   ],
   "source": [
    "perceptron_model=al.Perceptron(0.1, 200)\n",
    "pegasos_model=al.PegasosSVM(0.001, 500)\n",
    "logistic_model=al.RegLogisticClass(0.01, 500)\n",
    "perceptron_model.fit(X_train, Y_train)\n",
    "pegasos_model.fit(X_train, Y_train)\n",
    "logistic_model.fit(X_train, Y_train)\n",
    "loss_perceptron = sup.Zero_One_Loss(Y_test, perceptron_model.predict(X_test))\n",
    "loss_pegasos = sup.Zero_One_Loss(Y_test, pegasos_model.predict(X_test))\n",
    "loss_logistic = sup.Zero_One_Loss(Y_test, logistic_model.predict(X_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron}  \")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos}  \")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic}  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perceptron_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m col_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m      2\u001b[0m col_names\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdelete(col_names, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m sup\u001b[38;5;241m.\u001b[39mweights_comparison(\u001b[43mperceptron_model\u001b[49m\u001b[38;5;241m.\u001b[39mweights, pegasos_model\u001b[38;5;241m.\u001b[39mweights, logistic_model\u001b[38;5;241m.\u001b[39mweights, col_names)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perceptron_model' is not defined"
     ]
    }
   ],
   "source": [
    "col_names = [f'x{i+1}' for i in range(X.shape[1])]\n",
    "col_names=np.delete(col_names, 5)\n",
    "sup.weights_comparison(perceptron_model.weights, pegasos_model.weights, logistic_model.weights, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLYNOMIAL EXPANSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_poly_train, X_poly_test \u001b[38;5;241m=\u001b[39m sup\u001b[38;5;241m.\u001b[39mPolynomial_exp(X_train,X_test, \u001b[43mcol_names\u001b[49m)\n\u001b[0;32m      2\u001b[0m X_poly_train, X_poly_test \u001b[38;5;241m=\u001b[39m sup\u001b[38;5;241m.\u001b[39mStandardized(X_poly_train, X_poly_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'col_names' is not defined"
     ]
    }
   ],
   "source": [
    "X_poly_train, X_poly_test = sup.Polynomial_exp(X_train,X_test, col_names)\n",
    "X_poly_train, X_poly_test = sup.Standardized(X_poly_train, X_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_poly = X_poly_train.corr()\n",
    "high_corr_poly = correlation_matrix_poly[(correlation_matrix_poly > 0.9) | (correlation_matrix_poly < -0.9)]\n",
    "high_corr_poly = high_corr_poly[high_corr_poly != 1.0]\n",
    "high_corr_poly.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_perc_poly, param_perc_poly = sup.tuning_par(al.Perceptron, pd.DataFrame(X_poly_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos_poly, param_pegasos_poly = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_poly_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit_poly, param_logit_poly = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_poly_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc_poly, loss_perc_poly)\n",
    "print(param_pegasos_poly, loss_pegasos_poly)\n",
    "print(param_logit_poly, loss_logistic_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model_poly = al.Perceptron(1, 200)\n",
    "pegasos_model_poly = al.PegasosSVM(0.1, 500)\n",
    "logistic_model_poly = al.RegLogisticClass(0.01, 100)\n",
    "perceptron_model_poly.fit(X_poly_train, Y_train)\n",
    "pegasos_model_poly.fit(X_poly_train, Y_train)\n",
    "logistic_model_poly.fit(X_poly_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.10715544589354953\n",
      "0-1 Loss Pegasos : 0.33944307366936904\n",
      "0-1 Loss Logistic : 0.5830102220655622\n"
     ]
    }
   ],
   "source": [
    "loss_perceptron_poly = sup.Zero_One_Loss(Y_test, perceptron_model_poly.predict(X_poly_test))\n",
    "loss_pegasos_poly = sup.Zero_One_Loss(Y_test, pegasos_model_poly.predict(X_poly_test))\n",
    "loss_logistic_poly = sup.Zero_One_Loss(Y_test, logistic_model_poly.predict(X_poly_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron_poly}\")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos_poly}\")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic_poly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup.weights_comparison(perceptron_model_poly.weights, pegasos_model_poly.weights, logistic_model_poly.weights, X_poly_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m kernel_perc \u001b[38;5;241m=\u001b[39m al\u001b[38;5;241m.\u001b[39mKernelizedPerceptron(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mkernel_perc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred, weights \u001b[38;5;241m=\u001b[39m kernel_perc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Gulli\\Desktop\\Uni\\Magi\\MachineLearningandstat\\Progetto_ML\\Codes\\Final\\Algorithm.py:139\u001b[0m, in \u001b[0;36mKernelizedPerceptron.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[j] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[j] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY[j] \u001b[38;5;241m*\u001b[39m \u001b[43msup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#devi vedere come chiamare il \u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    141\u001b[0m         prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[j] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY[j] \u001b[38;5;241m*\u001b[39m sup\u001b[38;5;241m.\u001b[39mpolynomial_kernel(X[i], X[j], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md)\n",
      "File \u001b[1;32mc:\\Users\\Gulli\\Desktop\\Uni\\Magi\\MachineLearningandstat\\Progetto_ML\\Codes\\Final\\Support.py:150\u001b[0m, in \u001b[0;36mgaussian_kernel\u001b[1;34m(x1, x2, sigma)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgaussian_kernel\u001b[39m(x1, x2, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    x1: First input vector.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    kernel: The Gaussian kernel value between x1 and x2.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sigma \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Gulli\\Desktop\\Uni\\Magi\\MachineLearningandstat\\Progetto_ML\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2796\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2794\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2796\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2797\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernel_perc = al.KernelizedPerceptron('gaussian')\n",
    "kernel_perc.fit(X_train, Y_train)\n",
    "y_pred, weights = kernel_perc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_perc_pol = al.KernelizedPerceptron('polynomial')\n",
    "kernel_perc_pol.fit(X_train, Y_train)\n",
    "y_pred_pol, weights_pol = kernel_perc_pol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_pegasos_gaussian = al.KernelizedPegasos('gaussian')\n",
    "kernel_pegasos_gaussian.fit(X_train, Y_train)\n",
    "y_pred_pegasos, weights_pegasos = kernel_pegasos_gaussian.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Progetto_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
