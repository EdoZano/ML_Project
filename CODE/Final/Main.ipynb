{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mt\n",
    "import itertools as it\n",
    "import Algorithm as al\n",
    "import Support as sup\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.read_csv(\"C:/Users/edoar/Desktop/UNI/Magi/MachineLearningandstat/Progetto_ML/your_dataset.csv\")\n",
    "X=ds.iloc[:,:-1]\n",
    "Y=ds.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "y      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ds.isnull().sum())\n",
    "ds = ds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4992, 5008\n",
      "4571, 4885\n"
     ]
    }
   ],
   "source": [
    "count1=np.sum(Y==1)\n",
    "count_inv=np.sum(Y==-1)\n",
    "print(f'{count1}, {count_inv}') #number of labels before removing outliers\n",
    "\n",
    "X, Y = sup.Outliers(X, Y)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "Y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "count1=np.sum(Y==1)\n",
    "count_inv=np.sum(Y==-1)\n",
    "print(f'{count1}, {count_inv}') #number fo labels after removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "X_train, X_test, Y_train, Y_test = sup.Split(X, Y)\n",
    "X_train, X_test = sup.Standardized(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_param = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "pegasos_param = {\n",
    "    'lambda_par': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "logistic_param = {\n",
    "    'lambda_par': [0.001, 0.01, 0.1, 1],\n",
    "    'n': [50, 100, 200, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'n': 50} 0.33977527040289446\n",
      "{'lambda_par': 0.1, 'n': 500} 0.2822044165568765\n",
      "{'lambda_par': 0.1, 'n': 100} 0.5005156579922432\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "loss_perc_in, param_perc_in = sup.tuning_par(al.Perceptron, pd.DataFrame(X_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos_in, param_pegasos_in = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit_in, param_logit_in = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc_in, loss_perc_in)\n",
    "print(param_pegasos_in, loss_pegasos_in)\n",
    "print(param_logit_in, loss_logit_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.979744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.979744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  level_1         0\n",
       "0        2        5 -0.989999\n",
       "1        2        9 -0.979744\n",
       "2        5        2 -0.989999\n",
       "3        5        9  0.989808\n",
       "4        9        2 -0.979744\n",
       "5        9        5  0.989808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = pd.DataFrame(X_train).corr()\n",
    "high_corr = correlation_matrix[(correlation_matrix > 0.9) | (correlation_matrix < -0.9)]\n",
    "high_corr = high_corr[high_corr != 1.0]\n",
    "high_corr.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "perceptron_model=al.Perceptron(**param_perc_in)\n",
    "pegasos_model=al.PegasosSVM(**param_pegasos_in)\n",
    "logistic_model=al.RegLogisticClass(**param_logit_in)\n",
    "perceptron_model.fit(X_train, Y_train)\n",
    "pegasos_model.fit(X_train, Y_train)\n",
    "logistic_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.3489601691928093  \n",
      "0-1 Loss Pegasos : 0.3020796616143814  \n",
      "0-1 Loss Logistic : 0.6792386323581248  \n"
     ]
    }
   ],
   "source": [
    "loss_perceptron = sup.Zero_One_Loss(Y_test, perceptron_model.predict(X_test))\n",
    "loss_pegasos = sup.Zero_One_Loss(Y_test, pegasos_model.predict(X_test))\n",
    "loss_logistic = sup.Zero_One_Loss(Y_test, logistic_model.predict(X_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron}  \")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos}  \")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted losses for Perceptron:\n",
      "{(5, 9): np.float64(0.3193514275643285), (2, 9): np.float64(0.3239337328163553), (2, 5, 9): np.float64(0.33697567853366234), 2: np.float64(0.34966513923158266), 5: np.float64(0.35001762425096933), (2, 5): np.float64(0.39548819175185057), 9: np.float64(0.42051462812830454)}\n",
      "\n",
      "Sorted losses for Pegasos:\n",
      "{2: np.float64(0.3091293620021149), (2, 5): np.float64(0.3091293620021149), 9: np.float64(0.31018681706027496), (2, 5, 9): np.float64(0.3108917870990483), (2, 9): np.float64(0.312301727176595), (5, 9): np.float64(0.3168840324286218), 5: np.float64(0.31758900246739513)}\n",
      "\n",
      "Sorted losses for Logistic:\n",
      "{2: np.float64(0.4102925625660909), (5, 9): np.float64(0.4776172012689461), (2, 5): np.float64(0.5378921395840677), 5: np.float64(0.610504053577723), (2, 9): np.float64(0.6221360592174833), 9: np.float64(0.6263658794501233), (2, 5, 9): np.float64(0.6478674656327106)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "models=['Perceptron', 'Pegasos', 'Logistic']\n",
    "loss_dicts = {model: {} for model in models}  # Create a dictionary for each model\n",
    "for m in models:\n",
    "    for i in [2,5,9,[5,9],[2,5],[2,9],[2,5,9]]:\n",
    "        X_reduced_train=np.delete(X_train, i, axis=1)\n",
    "        X_reduced_test=np.delete(X_test, i, axis=1)\n",
    "        if m == 'Perceptron':\n",
    "            model = al.Perceptron(**param_perc_in)\n",
    "        elif m == 'Pegasos':\n",
    "            model = al.PegasosSVM(**param_pegasos_in)\n",
    "        else:\n",
    "            model = al.RegLogisticClass(**param_logit_in)\n",
    "        \n",
    "        model.fit(X_reduced_train, Y_train)\n",
    "        y_pred_test = model.predict(X_reduced_test)\n",
    "\n",
    "        loss_test = sup.Zero_One_Loss(Y_test, y_pred_test)\n",
    "\n",
    "        # Save test loss in the dictionary\n",
    "        loss_dicts[m][tuple(i) if isinstance(i, list) else i] = loss_test\n",
    "\n",
    "# Sort dictionaries by test loss in ascending order\n",
    "sorted_loss_dicts = {\n",
    "    model: dict(sorted(loss_dicts[model].items(), key=lambda item: item[1]))\n",
    "    for model in models\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Sorted losses for {model}:\")\n",
    "    print(sorted_loss_dicts[model])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To simplify our analysis we're gonna remove the same feature for all the models\n",
    "X_train=np.delete(X_train, (5,9), axis=1)\n",
    "X_test=np.delete(X_test, (5, 9), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOING TUNING AGAIN WITHOUT THE FEATUREs AND SEEING IF THE BEST PARAMETERS CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'n': 500} 0.3198037617458438\n",
      "{'lambda_par': 1, 'n': 200} 0.28055383251852195\n",
      "{'lambda_par': 0.1, 'n': 200} 0.538856735024245\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "loss_perc, param_perc = sup.tuning_par(al.Perceptron, pd.DataFrame(X_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos, param_pegasos = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit, param_logit = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc, loss_perc)\n",
    "print(param_pegasos, loss_pegasos)\n",
    "print(param_logit, loss_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.33803313359182235  \n",
      "0-1 Loss Pegasos : 0.3108917870990483  \n",
      "0-1 Loss Logistic : 0.5805428269298555  \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "perceptron_model=al.Perceptron(**param_perc)\n",
    "pegasos_model=al.PegasosSVM(**param_pegasos)\n",
    "logistic_model=al.RegLogisticClass(**param_logit)\n",
    "perceptron_model.fit(X_train, Y_train)\n",
    "pegasos_model.fit(X_train, Y_train)\n",
    "logistic_model.fit(X_train, Y_train)\n",
    "loss_perceptron = sup.Zero_One_Loss(Y_test, perceptron_model.predict(X_test))\n",
    "loss_pegasos = sup.Zero_One_Loss(Y_test, pegasos_model.predict(X_test))\n",
    "loss_logistic = sup.Zero_One_Loss(Y_test, logistic_model.predict(X_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron}  \")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos}  \")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic}  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Perceptron   Pegasos  Logistic_Regression\n",
      "0      x1    0.101221  0.102250             0.276443\n",
      "1      x2    0.099007  0.037272             0.154135\n",
      "2      x4    0.013334  0.157831             0.099160\n",
      "3      x5    0.099952  0.087353             0.064245\n",
      "4      x6    0.125197  0.032989             0.243959\n",
      "5      x7    0.066880  0.213053             0.059493\n",
      "6      x8    0.288993  0.218407             0.063198\n",
      "7      x9    0.205416  0.150844             0.039367\n"
     ]
    }
   ],
   "source": [
    "col_names = [f'x{i+1}' for i in range(X.shape[1])]\n",
    "col_names=np.delete(col_names, (2,9))\n",
    "sup.weights_comparison(perceptron_model.weights, pegasos_model.weights, logistic_model.weights, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLYNOMIAL EXPANSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_train, X_poly_test = sup.Polynomial_exp(X_train,X_test, col_names)\n",
    "X_poly_train, X_poly_test = sup.Standardized(X_poly_train, X_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [level_0, level_1, 0]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix_poly = X_poly_train.corr()\n",
    "high_corr_poly = correlation_matrix_poly[(correlation_matrix_poly > 0.9) | (correlation_matrix_poly < -0.9)]\n",
    "high_corr_poly = high_corr_poly[high_corr_poly != 1.0]\n",
    "high_corr_poly.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n': 200} 0.09004904817155868\n",
      "{'lambda_par': 0.1, 'n': 500} 0.17707420906904167\n",
      "{'lambda_par': 0.001, 'n': 200} 0.5333353838898031\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "loss_perc_poly, param_perc_poly = sup.tuning_par(al.Perceptron, pd.DataFrame(X_poly_train), pd.Series(Y_train), perceptron_param ,5)\n",
    "loss_pegasos_poly, param_pegasos_poly = sup.tuning_par(al.PegasosSVM, pd.DataFrame(X_poly_train), pd.Series(Y_train), pegasos_param, 5)\n",
    "loss_logit_poly, param_logit_poly = sup.tuning_par(al.RegLogisticClass, pd.DataFrame(X_poly_train), pd.Series(Y_train), logistic_param, 5)\n",
    "print(param_perc_poly, loss_perc_poly)\n",
    "print(param_pegasos_poly, loss_pegasos_poly)\n",
    "print(param_logit_poly, loss_logit_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(57)\n",
    "random.seed(57)\n",
    "perceptron_model_poly = al.Perceptron(**param_perc_poly)\n",
    "pegasos_model_poly = al.PegasosSVM(**param_pegasos_poly)\n",
    "logistic_model_poly = al.RegLogisticClass(**param_logit_poly)\n",
    "perceptron_model_poly.fit(X_poly_train, Y_train)\n",
    "pegasos_model_poly.fit(X_poly_train, Y_train)\n",
    "logistic_model_poly.fit(X_poly_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Perceptron : 0.10081071554458935\n",
      "0-1 Loss Pegasos : 0.15509340853013748\n",
      "0-1 Loss Logistic : 0.5904124074726824\n"
     ]
    }
   ],
   "source": [
    "loss_perceptron_poly = sup.Zero_One_Loss(Y_test, perceptron_model_poly.predict(X_poly_test))\n",
    "loss_pegasos_poly = sup.Zero_One_Loss(Y_test, pegasos_model_poly.predict(X_poly_test))\n",
    "loss_logistic_poly = sup.Zero_One_Loss(Y_test, logistic_model_poly.predict(X_poly_test))\n",
    "print(f\"0-1 Loss Perceptron : {loss_perceptron_poly}\")\n",
    "print(f\"0-1 Loss Pegasos : {loss_pegasos_poly}\")\n",
    "print(f\"0-1 Loss Logistic : {loss_logistic_poly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Perceptron   Pegasos  Logistic_Regression\n",
      "0       x1    0.029723  0.018755             0.012947\n",
      "1       x2    0.012261  0.003791             0.019130\n",
      "2       x4    0.019293  0.032400             0.012854\n",
      "3       x5    0.013991  0.023269             0.068071\n",
      "4       x6    0.050148  0.045630             0.011240\n",
      "5       x7    0.030828  0.048297             0.033070\n",
      "6       x8    0.130420  0.102653             0.034310\n",
      "7       x9    0.045660  0.036568             0.040627\n",
      "8     x1^2    0.025479  0.014881             0.005247\n",
      "9     x2^2    0.013678  0.021167             0.017018\n",
      "10    x4^2    0.001793  0.009556             0.016568\n",
      "11    x5^2    0.009642  0.005888             0.006625\n",
      "12    x6^2    0.000222  0.007354             0.026625\n",
      "13    x7^2    0.002278  0.007043             0.064211\n",
      "14    x8^2    0.023271  0.022661             0.019364\n",
      "15    x9^2    0.019254  0.011414             0.004047\n",
      "16   x1*x2    0.001791  0.045142             0.020167\n",
      "17   x1*x4    0.010337  0.011726             0.006102\n",
      "18   x1*x5    0.012202  0.000950             0.058307\n",
      "19   x1*x6    0.013840  0.013707             0.018778\n",
      "20   x1*x7    0.003134  0.015098             0.028861\n",
      "21   x1*x8    0.062778  0.035127             0.023787\n",
      "22   x1*x9    0.005886  0.029593             0.033030\n",
      "23   x2*x4    0.017584  0.013556             0.019619\n",
      "24   x2*x5    0.007128  0.015782             0.011697\n",
      "25   x2*x6    0.006420  0.006240             0.002848\n",
      "26   x2*x7    0.009168  0.032212             0.029705\n",
      "27   x2*x8    0.005600  0.024008             0.010173\n",
      "28   x2*x9    0.225822  0.121900             0.008500\n",
      "29   x4*x5    0.015974  0.025103             0.059413\n",
      "30   x4*x6    0.010154  0.016259             0.004416\n",
      "31   x4*x7    0.014095  0.003553             0.037498\n",
      "32   x4*x8    0.011352  0.000223             0.027402\n",
      "33   x4*x9    0.006451  0.016133             0.035109\n",
      "34   x5*x6    0.004998  0.002947             0.007354\n",
      "35   x5*x7    0.004616  0.009669             0.040821\n",
      "36   x5*x8    0.071052  0.057943             0.008725\n",
      "37   x5*x9    0.004586  0.007285             0.032384\n",
      "38   x6*x7    0.002251  0.021093             0.002187\n",
      "39   x6*x8    0.018642  0.001005             0.014430\n",
      "40   x6*x9    0.003072  0.026430             0.000172\n",
      "41   x7*x8    0.004912  0.009110             0.033460\n",
      "42   x7*x9    0.011913  0.018874             0.021100\n",
      "43   x8*x9    0.006303  0.008007             0.011998\n"
     ]
    }
   ],
   "source": [
    "sup.weights_comparison(perceptron_model_poly.weights, pegasos_model_poly.weights, logistic_model_poly.weights, X_poly_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_perc = al.KernelizedPerceptron('gaussian')\n",
    "kernel_perc.fit(X_train, Y_train)\n",
    "y_pred, weights = kernel_perc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_perc_pol = al.KernelizedPerceptron('polynomial')\n",
    "kernel_perc_pol.fit(X_train, Y_train)\n",
    "y_pred_pol, weights_pol = kernel_perc_pol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Kernelized-Perceptron Gaussian : 0.062037363412054986\n",
      "0-1 Loss Kernelized-Perceptron Polynomial : 0.09058864998237574\n"
     ]
    }
   ],
   "source": [
    "loss_kernel_perceptron = sup.Zero_One_Loss(Y_test, y_pred)\n",
    "loss_Kernel_poly = sup.Zero_One_Loss(Y_test, y_pred_pol)\n",
    "print(f\"0-1 Loss Kernelized-Perceptron Gaussian : {loss_kernel_perceptron}\")\n",
    "print(f\"0-1 Loss Kernelized-Perceptron Polynomial : {loss_Kernel_poly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_pegasos_gaussian = al.KernelizedPegasos('gaussian')\n",
    "kernel_pegasos_gaussian.fit(X_train, Y_train)\n",
    "y_pred_kernel_pegasos, weights_kernel_pegasos = kernel_pegasos_gaussian.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_pegasos_poly = al.KernelizedPegasos('polynomial')\n",
    "kernel_pegasos_poly.fit(X_train, Y_train)\n",
    "y_pred_kernel_pegasos_poly, weights_kernel_pegasos_poly = kernel_pegasos_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 Loss Kernelized-Pegasos Gaussian:0.212195981670779\n",
      "0-1 Loss Kernelized-Pegasos Gaussian:0.2016214310891787\n"
     ]
    }
   ],
   "source": [
    "loss_kernel_pegasos = sup.Zero_One_Loss(Y_test, y_pred_kernel_pegasos)\n",
    "loss_kernel_pegasos_poly = sup.Zero_One_Loss(Y_test, y_pred_kernel_pegasos_poly)\n",
    "print(f\"0-1 Loss Kernelized-Pegasos Gaussian:{loss_kernel_pegasos}\")\n",
    "print(f\"0-1 Loss Kernelized-Pegasos Gaussian:{loss_kernel_pegasos_poly}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Progetto_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
